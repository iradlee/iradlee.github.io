<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <description></description>
    <link>/</link>
    <atom:link href="/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 27 Sep 2015 10:14:48 +0200</pubDate>
    <lastBuildDate>Sun, 27 Sep 2015 10:14:48 +0200</lastBuildDate>
    <generator>Jekyll v2.5.3</generator>
    
      <item>
        <title>Blackboxing</title>
        <description>&lt;p&gt;&amp;quot;When a machine runs efficiently, when a matter of fact is settled, one need focus only on its inputs and outputs and not on its internal complexity. Thus, paradoxically, the more science and technology succeed, the more opaque and obscure they become.&amp;quot;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Bruno Latour&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 27 Sep 2015 12:00:00 +0200</pubDate>
        <link>/2015/09/blackboxing</link>
        <guid isPermaLink="true">/2015/09/blackboxing</guid>
        
        
      </item>
    
      <item>
        <title>Web Audio API Experiment nr.1</title>
        <description>&lt;p&gt;Loading, playing and visualizing sound using Web Audio API.&lt;/p&gt;

&lt;p&gt;&lt;html xmlns=&quot;http://www.w3.org/1999/html&quot;&gt;
&lt;head&gt;
    &lt;script type=&quot;text/javascript&quot; src=&quot;https://rawgit.com/josdirksen/smartjava/master/webaudio/jquery-1.8.0.min.js&quot;&gt;&lt;/script&gt;
&lt;/head&gt;&lt;/p&gt;

&lt;canvas id=&quot;canvas&quot; width=&quot;680&quot; height=&quot;325&quot; style=&quot;display: block;&quot;&gt;&lt;/canvas&gt;

&lt;script type=&quot;text/javascript&quot;&gt;
    // create the audio context (chrome only for now)
    if (! window.AudioContext) {
        if (! window.webkitAudioContext) {
            alert(&#39;no audiocontext found&#39;);
        }
        window.AudioContext = window.webkitAudioContext;
    }
    var context = new AudioContext();
    var audioBuffer;
    var sourceNode;
    var analyser;
    var javascriptNode;

    // get the context from the canvas to draw on
    var ctx = $(&quot;#canvas&quot;).get()[0].getContext(&quot;2d&quot;);

    // create a gradient for the fill. Note the strange
    // offset, since the gradient is calculated based on
    // the canvas, not the specific element we draw

    var gradient = ctx.createLinearGradient(0, 0, 0, 300);

    gradient.addColorStop(1, &#39;#DF01A5&#39;);
    gradient.addColorStop(0.75, &#39;#DF01A5&#39;);
    gradient.addColorStop(0.25, &#39;#DF01A5&#39;);
    gradient.addColorStop(0, &#39;#DF01A5&#39;);


    // load the sound
    setupAudioNodes();
    loadSound(&quot;https://archive.org/download/pc0509-01/pc0509-01_-_rene_munoz_cordova_-_02_-_ustarma_kurtal.ogg&quot;);
   // loadSound(&quot;https://archive.org/download/pc0509-01/pc0509-01_-_rene_munoz_cordova_-_06_-_ver_hurtam.ogg&quot;);   
    

    function setupAudioNodes() {

        // setup a javascript node
        javascriptNode = context.createScriptProcessor(2048, 1, 1);
        // connect to destination, else it isn&#39;t called
        javascriptNode.connect(context.destination);


        // setup a analyzer
        analyser = context.createAnalyser();
        analyser.smoothingTimeConstant = 0.3;
        analyser.fftSize = 512;

        // create a buffer source node
        sourceNode = context.createBufferSource();
        sourceNode.connect(analyser);
        analyser.connect(javascriptNode);

        sourceNode.connect(context.destination);
    }

    // load the specified sound
    function loadSound(url) {
        var request = new XMLHttpRequest();
        request.open(&#39;GET&#39;, url, true);
        request.responseType = &#39;arraybuffer&#39;;

        // When loaded decode the data
        request.onload = function() {

            // decode the data
            context.decodeAudioData(request.response, function(buffer) {
                // when the audio is decoded play the sound
                playSound(buffer);
            }, onError);
        }
        request.send();
    }


    function playSound(buffer) {
        sourceNode.buffer = buffer;
        sourceNode.start(0);
    }

    // log if an error occurs
    function onError(e) {
        console.log(e);
    }

    // when the javascript node is called
    // we use information from the analyzer node
    // to draw the volume
    javascriptNode.onaudioprocess = function() {

        // get the average for the first channel
        var array =  new Uint8Array(analyser.frequencyBinCount);
        analyser.getByteFrequencyData(array);

        // clear the current state
        ctx.clearRect(0, 0, 680, 325);

        // set the fill style
        ctx.fillStyle=gradient;
        drawSpectrum(array);

    }


    function drawSpectrum(array) {
        for ( var i = 0; i &lt; (array.length); i++ ){
            var value = array[i];

            ctx.fillRect(i*5,325-value,3,325);
            //  console.log([i,value])
        }
    };

&lt;/script&gt;

&lt;p&gt;&lt;/html&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 28 Jan 2015 16:00:00 +0100</pubDate>
        <link>/2015/01/webaudio-api</link>
        <guid isPermaLink="true">/2015/01/webaudio-api</guid>
        
        
      </item>
    
      <item>
        <title>Hello World</title>
        <description>&lt;p&gt;Welcome to my new home on the web.
&lt;div class=&quot;img img-big&quot;&gt;
    &lt;img src=&quot;/assets/hello.jpg&quot;&gt;
&lt;/div&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 25 Jan 2015 15:00:00 +0100</pubDate>
        <link>/2015/01/hello-world</link>
        <guid isPermaLink="true">/2015/01/hello-world</guid>
        
        
        <category>hello</category>
        
      </item>
    
  </channel>
</rss>
